{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6abeba71-1e3c-4eda-88a6-0fbf12f546e1",
   "metadata": {},
   "source": [
    "任务2总体思路\n",
    "\n",
    "特征：\n",
    "E0..E9（语义嵌入 10 维） + 7 个音频特征（0–1 归一）\n",
    "支持数值块/嵌入块的加权（避免某一块支配）\n",
    "\n",
    "降维（可选但推荐）：PCA 把 17 维 → 10 ，降噪、便于聚类\n",
    "\n",
    "聚类： KMeans，用 肘部法 + 轮廓系数 选 K；\n",
    "\n",
    "检索：给定歌曲 id → 找到其簇 C → 只在簇内做相似度排序（余弦），取 Top-K。\n",
    "这样主题一致性更强、效率也更高。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d5d557-96c0-4543-a787-3009b563aa9d",
   "metadata": {},
   "source": [
    "训练脚本（聚类模型产出 + 工件保存）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "453701c5-65cc-4d30-a559-e8aaae464c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 预处理完成，可直接用于聚类\n",
      "                       id                  Title  Danceability    Energy  \\\n",
      "0  003vvx7Niy0yvhvHt4a68B         Mr. Brightside      0.216321  0.906459   \n",
      "1  00Ga884hbpVvCNyeQdle1U       Violet Chemistry      0.591969  0.688196   \n",
      "2  02FaKXXL7KUtRc7K0k54tL  Cozy Little Christmas      0.762953  0.569042   \n",
      "\n",
      "    Valence  Loudness  Speechiness  Acousticness  Instrumentalness      E0  \\\n",
      "0  0.211477  0.999725     0.084691      0.001006               0.0  0.1148   \n",
      "1  0.585547  0.746225     0.026059      0.003018               0.0  0.0688   \n",
      "2  0.555792  0.721656     0.171010      0.128773               0.0  0.0579   \n",
      "\n",
      "       E1      E2      E3      E4      E5      E6      E7      E8      E9  \n",
      "0  0.0401  0.1039  0.0970 -0.0332 -0.0449  0.2025  0.1399 -0.2235 -0.1483  \n",
      "1  0.0480  0.0838  0.0890 -0.0333 -0.0059  0.2176  0.1298 -0.2488 -0.1638  \n",
      "2  0.0626  0.0661  0.0605 -0.0436 -0.0274  0.1789  0.1501 -0.2526 -0.1877  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Edit\\Anaconda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "D:\\Edit\\Anaconda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "D:\\Edit\\Anaconda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "D:\\Edit\\Anaconda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "D:\\Edit\\Anaconda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette by K: {6: 0.18599577377188012, 8: 0.1606890969199683, 10: 0.15231824195291613, 12: 0.15040373195291148, 14: 0.14468193768355264} → best_k = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Edit\\Anaconda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\Akari\\OneDrive\\Desktop\\SEM 1\\AML\\Final CW\\datas\\artifacts_task2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, joblib\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"4\"  \n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "\n",
    "# 1️⃣ 读取 Task1 的结果文件\n",
    "CSV = Path(r\"C:\\Users\\Akari\\OneDrive\\Desktop\\SEM 1\\AML\\Final CW\\datas\\spotify_preprocess.csv\")\n",
    "df = pd.read_csv(CSV)\n",
    "\n",
    "# 2️⃣ 拆分 Embedding_10d 为 10 列\n",
    "def split_embed(s):\n",
    "    parts = [float(x) for x in str(s).split(',') if x != \"\"]\n",
    "    if len(parts) < 10:\n",
    "        parts += [0.0]*(10-len(parts))\n",
    "    return parts[:10]\n",
    "\n",
    "embeds = np.vstack(df['Embedding_10d'].apply(split_embed))\n",
    "embed_cols = [f'E{i}' for i in range(10)]\n",
    "for i, c in enumerate(embed_cols):\n",
    "    df[c] = embeds[:, i]\n",
    "\n",
    "# 3️⃣ 删除原字符串列（可选）\n",
    "df.drop(columns=['Embedding_10d'], inplace=True)\n",
    "\n",
    "# 4️⃣ 现在 df 就可以直接用于 Task2 的 PCA / KMeans\n",
    "print(\"✅ 预处理完成，可直接用于聚类\")\n",
    "print(df.head(3))\n",
    "\n",
    "EMB_COLS = [f\"E{i}\" for i in range(10)]\n",
    "NUM_COLS = ['Danceability','Energy','Valence','Loudness','Speechiness','Acousticness','Instrumentalness']\n",
    "\n",
    "# --- 特征加权（可调） ---\n",
    "W_EMB = 1.0\n",
    "W_NUM = 1.0\n",
    "X = np.hstack([df[EMB_COLS].values * W_EMB,\n",
    "               df[NUM_COLS].values * W_NUM])\n",
    "\n",
    "# --- PCA（可选） ---\n",
    "USE_PCA = True\n",
    "PCA_DIM = 10\n",
    "if USE_PCA:\n",
    "    pca = PCA(n_components=PCA_DIM, random_state=42)\n",
    "    Xp = pca.fit_transform(X)\n",
    "else:\n",
    "    pca, Xp = None, X\n",
    "\n",
    "# --- 选 K：粗扫 + 指标 ---\n",
    "candidates = [6,8,10,12,14]\n",
    "scores = {}\n",
    "for k in candidates:\n",
    "    km = KMeans(n_clusters=k, n_init=20, random_state=42)\n",
    "    lab = km.fit_predict(Xp)\n",
    "    sil = silhouette_score(Xp, lab)\n",
    "    scores[k] = sil\n",
    "best_k = max(scores, key=scores.get)\n",
    "print(\"Silhouette by K:\", scores, \"→ best_k =\", best_k)\n",
    "\n",
    "# --- 用 best_k 重新训练 ---\n",
    "kmeans = KMeans(n_clusters=best_k, n_init=50, random_state=42)\n",
    "labels = kmeans.fit_predict(Xp)\n",
    "\n",
    "# --- 保存工件 ---\n",
    "out_dir = Path(r\"C:\\Users\\Akari\\OneDrive\\Desktop\\SEM 1\\AML\\Final CW\\datas\\artifacts_task2\"); out_dir.mkdir(exist_ok=True)\n",
    "df_out = df.copy()\n",
    "df_out[\"cluster\"] = labels\n",
    "df_out.to_csv(out_dir/\"clustered_catalog.csv\", index=False)\n",
    "\n",
    "joblib.dump({\"kmeans\": kmeans, \"pca\": pca, \"W_EMB\": W_EMB, \"W_NUM\": W_NUM,\n",
    "             \"EMB_COLS\": EMB_COLS, \"NUM_COLS\": NUM_COLS},\n",
    "            out_dir/\"cluster_model.pkl\")\n",
    "print(\"Saved:\", out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a28356-f4a5-446a-a37d-160844806b58",
   "metadata": {},
   "source": [
    "在线推荐函数（簇内 Top-K）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0304e1b-1857-47bb-8804-017a5bdb3d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rank                      id                                   Title  \\\n",
      "48      1  0QfZ8OHFnFzLe66iFBww2U                              Lux Æterna   \n",
      "367     2  2nLtzopw4rPReszdYBJU6h                                    Numb   \n",
      "83      3  0kAZ3H6G9Zac4PMpmobMkj  If This Was A Movie (Taylor's Version)   \n",
      "651     4  4qzEjmuz380jeiBJp31oDY                                Chemical   \n",
      "545     5  456WNXWhDwYOSf5SpTuqxd                       Dog Days Are Over   \n",
      "105     6  0rc1HCVoReqzzXF9jssqZk                     Special (feat. SZA)   \n",
      "750     7  5TOgxgZrIZzvaKg9r2bvc2                                Chemical   \n",
      "787     8  5w40ZYhbBMAlHYNDaVJIUu                                Chemical   \n",
      "800     9  60a0Rd6pjrkxjPbaKzXjfq                              In the End   \n",
      "736    10  5NzfnUyVaNrxa2VtoyBWlR                       Tennessee Numbers   \n",
      "\n",
      "        score  \n",
      "48   0.963233  \n",
      "367  0.934037  \n",
      "83   0.924499  \n",
      "651  0.921819  \n",
      "545  0.913799  \n",
      "105  0.912106  \n",
      "750  0.909570  \n",
      "787  0.908711  \n",
      "800  0.907533  \n",
      "736  0.905948  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, joblib\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Akari\\OneDrive\\Desktop\\SEM 1\\AML\\Final CW\\Datas\\artifacts_task2\\clustered_catalog.csv\")\n",
    "model = joblib.load(r\"C:\\Users\\Akari\\OneDrive\\Desktop\\SEM 1\\AML\\Final CW\\Datas\\artifacts_task2\\cluster_model.pkl\")\n",
    "kmeans = model[\"kmeans\"]; pca = model[\"pca\"]\n",
    "EMB_COLS, NUM_COLS = model[\"EMB_COLS\"], model[\"NUM_COLS\"]\n",
    "W_EMB, W_NUM = model[\"W_EMB\"], model[\"W_NUM\"]\n",
    "\n",
    "def _build_features(subdf):\n",
    "    X = np.hstack([subdf[EMB_COLS].values * W_EMB, subdf[NUM_COLS].values * W_NUM])\n",
    "    return pca.transform(X) if pca is not None else X\n",
    "\n",
    "# 预计算簇特征（可放缓存）\n",
    "Xp = _build_features(df)\n",
    "\n",
    "# id -> index\n",
    "ID2IDX = {sid: i for i, sid in enumerate(df[\"id\"])}\n",
    "\n",
    "def recommend_cluster(song_id, k=10, diversify=False):\n",
    "    if song_id not in ID2IDX:\n",
    "        raise ValueError(f\"id '{song_id}' 不存在\")\n",
    "    q = ID2IDX[song_id]\n",
    "    c = df.loc[q, \"cluster\"]\n",
    "\n",
    "    # 只取同簇候选\n",
    "    idxs = np.where(df[\"cluster\"].values == c)[0]\n",
    "    Xc = Xp[idxs]; qv = Xp[q:q+1]\n",
    "\n",
    "    # 余弦得分\n",
    "    sims = cosine_similarity(qv, Xc).ravel()\n",
    "\n",
    "    # 排除自己，取 Top-K\n",
    "    mask = (idxs != q)\n",
    "    idxs, sims = idxs[mask], sims[mask]\n",
    "    k = min(k, len(idxs))\n",
    "    order = np.argsort(sims)[-k:][::-1]\n",
    "    idx_top = idxs[order]; sim_top = sims[order]\n",
    "\n",
    "    out = df.iloc[idx_top][[\"id\",\"Title\"]].copy()\n",
    "    out[\"score\"] = sim_top\n",
    "    out.insert(0, \"rank\", np.arange(1, k+1))\n",
    "\n",
    "    if diversify:\n",
    "        # 简单“同艺人降权”示例（Title 中艺人不在时可改成 Artists 列）\n",
    "        # 这里假设 df 有 Artists 列；若没有可忽略此块或改为基于 Title 的去重。\n",
    "        if \"Artists\" in df.columns:\n",
    "            artists_q = set(str(df.loc[q, \"Artists\"]).split(\" \"))\n",
    "            penalty = out.index.to_series().apply(\n",
    "                lambda i: 0.9 if artists_q & set(str(df.loc[i, \"Artists\"]).split(\" \")) else 1.0\n",
    "            ).values\n",
    "            out[\"score\"] = out[\"score\"] * penalty\n",
    "            out = out.sort_values(\"score\", ascending=False).head(k).reset_index(drop=True)\n",
    "            out[\"rank\"] = np.arange(1, len(out)+1)\n",
    "\n",
    "    return out\n",
    "\n",
    "# 使用：\n",
    "print(recommend_cluster(\"003vvx7Niy0yvhvHt4a68B\", k=10, diversify=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc2ee32-d0d5-47ea-a202-43c272be9709",
   "metadata": {},
   "source": [
    "读取 cluster_model.pkl 和 clustered_catalog.csv\n",
    "打印出模型里有哪些对象、KMeans/PCA 关键信息、簇大小分布、每簇示例，以及一个快速的 silhouette score 复核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e78be6ec-84e3-42b5-b644-8357243f916d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载模型文件: C:\\Users\\Akari\\OneDrive\\Desktop\\SEM 1\\AML\\Final CW\\Datas\\artifacts_task2\\cluster_model.pkl\n",
      "加载数据文件: C:\\Users\\Akari\\OneDrive\\Desktop\\SEM 1\\AML\\Final CW\\Datas\\artifacts_task2\\clustered_catalog.csv\n",
      "\n",
      "=== 模型概要 ===\n",
      "KMeans 聚类数: 6\n",
      "使用 PCA: True\n",
      "嵌入权重: 1.0  数值特征权重: 1.0\n",
      "嵌入列: ['E0', 'E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9']\n",
      "数值列: ['Danceability', 'Energy', 'Valence', 'Loudness', 'Speechiness', 'Acousticness', 'Instrumentalness']\n",
      "\n",
      "=== 簇大小分布 ===\n",
      "Cluster 0: 110 首歌\n",
      "Cluster 1: 92 首歌\n",
      "Cluster 2: 244 首歌\n",
      "Cluster 3: 115 首歌\n",
      "Cluster 4: 308 首歌\n",
      "Cluster 5: 137 首歌\n",
      "\n",
      "=== 每簇示例（前 5 首） ===\n",
      "\n",
      "[Cluster 0]\n",
      "                    id                 Title\n",
      "02FaKXXL7KUtRc7K0k54tL Cozy Little Christmas\n",
      "0EgLxY52mpGsXETyEsgVlP                  HOPE\n",
      "0FirgnvrpCkkhdaq64Gfen                YANKEE\n",
      "0T2pB7P1VdXPhLdQZ488uH                Normal\n",
      "0WoVfPjxsf9MTvPt9ptqeE           SLUT ME OUT\n",
      "\n",
      "[Cluster 1]\n",
      "                    id                                               Title\n",
      "0B7wvvmu9EISAwZnOpjhNI                                 When I Was Your Man\n",
      "0H1zX27yxoDrsrQA1hk5Uq                              O Come All Ye Faithful\n",
      "0HEzuLLojblUOaUSdmJ9gl Did you know that there's a tunnel under Ocean Blvd\n",
      "0JM8LI4HxrQs2Reqr2naYo                          All I Want (For Christmas)\n",
      "0Oqxt6JixieLHbwMfnJGWO                           Paris, Texas (feat. SYML)\n",
      "\n",
      "[Cluster 2]\n",
      "                    id                                           Title\n",
      "003vvx7Niy0yvhvHt4a68B                                  Mr. Brightside\n",
      "02dRkCEc8Q5ch4TTcnLxOn Nothing Breaks Like a Heart (feat. Miley Cyrus)\n",
      "03hyZKbj9GWZXD8jALwJA3                  Metro Spider (with Young Thug)\n",
      "04CqLjewJiSAqM210vZAmT                                           River\n",
      "07bsRv0pcpbG4zJeLsUs1p                                     Eyes Closed\n",
      "\n",
      "[Cluster 3]\n",
      "                    id                             Title\n",
      "02MWAaffLxlfxAUY7c5dvx                        Heat Waves\n",
      "04ndZkbKGthTgYSv3xS7en                            Cupido\n",
      "09OojFvtrM9YRzRjnXqJjA Rockin' Around The Christmas Tree\n",
      "0DWdj2oZMBFSzRsi2Cvfzf                               TQG\n",
      "0JmnkIqdlnUzPaf8sqBRs3                         Moonlight\n",
      "\n",
      "[Cluster 4]\n",
      "                    id                                    Title\n",
      "00Ga884hbpVvCNyeQdle1U                         Violet Chemistry\n",
      "02VBYrHfVwfEWXk5DXyf0T                      Leave The Door Open\n",
      "03fs6oV5JAlbytRYf3371S                        Everything I Love\n",
      "086myS9r57YsLbJpU0TgK9 Why'd You Only Call Me When You're High?\n",
      "0CYTGMBYkwUxrj1MWDLrC5                   CHORRITO PA LAS ANIMAS\n",
      "\n",
      "[Cluster 5]\n",
      "                    id                                            Title\n",
      "0A1JLUlkZkp2EFrosoNQi0                                        Labyrinth\n",
      "0Ie5uiv54KgCr7P4sYDTHl Baby It's Cold Outside (duet with Michael Bublé)\n",
      "0JIhRhZPF5j5dx0FGqTWxy                                  I'll Be Waiting\n",
      "0OoNzMdPSgbkM5MkcuEZfm          Lock On Me (with Travis Scott & Future)\n",
      "0PAcdVzhPO4gq1Iym9ESnK                                 Thinkin' Bout Me\n",
      "\n",
      "模型整体轮廓系数 (silhouette score): 0.1859\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# === 1️⃣ 指定文件路径 ===\n",
    "ART_DIR = r\"C:\\Users\\Akari\\OneDrive\\Desktop\\SEM 1\\AML\\Final CW\\Datas\\artifacts_task2\"\n",
    "\n",
    "model_path = os.path.join(ART_DIR, \"cluster_model.pkl\")\n",
    "catalog_path = os.path.join(ART_DIR, \"clustered_catalog.csv\")\n",
    "\n",
    "print(\"加载模型文件:\", model_path)\n",
    "print(\"加载数据文件:\", catalog_path)\n",
    "\n",
    "# === 2️⃣ 加载模型与数据 ===\n",
    "model = joblib.load(model_path)\n",
    "df = pd.read_csv(catalog_path)\n",
    "\n",
    "# === 3️⃣ 解包模型内容 ===\n",
    "kmeans = model.get(\"kmeans\")\n",
    "pca = model.get(\"pca\")\n",
    "W_EMB = model.get(\"W_EMB\", 1.0)\n",
    "W_NUM = model.get(\"W_NUM\", 1.0)\n",
    "EMB_COLS = model.get(\"EMB_COLS\", [])\n",
    "NUM_COLS = model.get(\"NUM_COLS\", [])\n",
    "\n",
    "print(\"\\n=== 模型概要 ===\")\n",
    "print(\"KMeans 聚类数:\", getattr(kmeans, \"n_clusters\", \"未知\"))\n",
    "print(\"使用 PCA:\", pca is not None)\n",
    "print(\"嵌入权重:\", W_EMB, \" 数值特征权重:\", W_NUM)\n",
    "print(\"嵌入列:\", EMB_COLS)\n",
    "print(\"数值列:\", NUM_COLS)\n",
    "\n",
    "# === 4️⃣ 检查簇分布 ===\n",
    "if \"cluster\" not in df.columns:\n",
    "    raise ValueError(\"数据中没有 'cluster' 列，请确认文件是否正确。\")\n",
    "\n",
    "print(\"\\n=== 簇大小分布 ===\")\n",
    "counts = df[\"cluster\"].value_counts().sort_index()\n",
    "for c, n in counts.items():\n",
    "    print(f\"Cluster {c}: {n} 首歌\")\n",
    "\n",
    "# === 5️⃣ 每个簇展示前 5 首歌 ===\n",
    "show_cols = [c for c in [\"id\", \"Title\"] if c in df.columns]\n",
    "print(\"\\n=== 每簇示例（前 5 首） ===\")\n",
    "for c in counts.index:\n",
    "    sub = df[df[\"cluster\"] == c].head(5)\n",
    "    print(f\"\\n[Cluster {c}]\")\n",
    "    print(sub[show_cols].to_string(index=False))\n",
    "\n",
    "# === 6️⃣ 计算 silhouette 分数（复核模型质量） ===\n",
    "try:\n",
    "    X = np.hstack([\n",
    "        df[EMB_COLS].values * W_EMB,\n",
    "        df[NUM_COLS].values * W_NUM\n",
    "    ])\n",
    "    if pca is not None:\n",
    "        X = pca.transform(X)\n",
    "    labels = df[\"cluster\"].values\n",
    "    sil = silhouette_score(X, labels)\n",
    "    print(f\"\\n模型整体轮廓系数 (silhouette score): {sil:.4f}\")\n",
    "except Exception as e:\n",
    "    print(\"\\n无法计算 silhouette：\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b1cbd8-b9ba-4698-b0bf-1371feb8830f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
