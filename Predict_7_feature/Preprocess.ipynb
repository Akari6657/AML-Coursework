{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019be56b-7f36-4186-b6f7-62508f389f2e",
   "metadata": {},
   "source": [
    "合并同一首歌的多行（多艺人/多国籍、多日期）\n",
    "\n",
    "7 个音频特征做 Min-Max 归一化\n",
    "\n",
    "排名取该歌历史最优名次（最小 Rank）\n",
    "\n",
    "上榜天数= 该歌在不同日期出现的去重天数\n",
    "\n",
    "最后只保留：id, Title, Artists, Nationality, 7个音频特征, Rank, DaysOnChart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7973b8fc-5ce1-43f9-b4b8-d09e3f75ae10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing groups: 100%|█████████████████████████████████████████████████████████| 9161/9161 [00:04<00:00, 2136.77it/s]\n",
      "Processing groups: 100%|█████████████████████████████████████████████████████████| 9161/9161 [00:01<00:00, 7826.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 预处理完成：C:\\Users\\Akari\\OneDrive\\Desktop\\SEM 1\\AML\\Final CW\\Datas\\spotify_preprocess_dayAndRank.csv  共 9161 首歌\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "预处理说明：\n",
    "- 输入：原始 CSV，以 ';' 分隔，包含每日榜单前200（2017/01/01 ~ 2023/05/31）\n",
    "- 目标：合并到歌曲级（id），保留：\n",
    "  id, Title, Artists(去重拼接), Nationality(去重拼接),\n",
    "  7个音频特征(均值后再MinMax归一化), Rank(历史最优名次), DaysOnChart(上榜去重天数)\n",
    "- 进度：对耗时的 groupby-apply 加 tqdm 进度条\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========= 可配置路径 =========\n",
    "SRC = Path(r\"C:\\Users\\Akari\\OneDrive\\Desktop\\SEM 1\\AML\\Final CW\\Datas\\Spotify_Dataset_V3.csv\")         # 原始CSV（;分隔）\n",
    "OUT = Path(r\"C:\\Users\\Akari\\OneDrive\\Desktop\\SEM 1\\AML\\Final CW\\Datas\\spotify_preprocess_dayAndRank.csv\")         # 输出CSV\n",
    "\n",
    "# ========= 工具函数 =========\n",
    "def split_artists(s: str):\n",
    "    \"\"\"把 Artists 列里可能出现的制表符/逗号等分隔统一拆分为列表。\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return []\n",
    "    s = str(s).replace('\\t', ',').replace('  ', ' ')\n",
    "    parts = [p.strip() for p in s.replace(' ,', ',').split(',') if p.strip()]\n",
    "    return parts\n",
    "\n",
    "def uniq_preserve_order(seq):\n",
    "    \"\"\"去重并保序。\"\"\"\n",
    "    return list(dict.fromkeys(seq))\n",
    "\n",
    "# tqdm 设置（支持 groupby 的 progress_apply）\n",
    "tqdm.pandas(desc=\"Processing groups\")\n",
    "\n",
    "# ========= Step 0: 读取 =========\n",
    "df = pd.read_csv(SRC, delimiter=';', dtype=str)\n",
    "\n",
    "# 转数值列\n",
    "num_cols = ['Danceability','Energy','Loudness','Speechiness','Acousticness','Instrumentalness','Valence','Rank']\n",
    "for c in num_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# 解析日期\n",
    "if 'Date' in df.columns:\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format=\"%d/%m/%Y\", errors='coerce')\n",
    "\n",
    "# 基础清理\n",
    "df = df.dropna(subset=['id'])\n",
    "df['Title'] = df['Title'].fillna('')\n",
    "\n",
    "# 存在性探测\n",
    "has_single_artist = 'Artist (Ind.)' in df.columns\n",
    "has_artists       = 'Artists' in df.columns\n",
    "has_single_nat    = 'Nationality' in df.columns\n",
    "\n",
    "# ========= Step 1: DaysOnChart（按 id-日期 去重后计数）=========\n",
    "if 'Date' in df.columns:\n",
    "    # 每日同一首歌可能多行（多艺人），去重到 (id, Date)\n",
    "    days_per_id = (df.dropna(subset=['Date'])\n",
    "                     .drop_duplicates(subset=['id', 'Date'])\n",
    "                     .groupby('id')['Date']\n",
    "                     .nunique()\n",
    "                     .rename('DaysOnChart')\n",
    "                     .astype(int))\n",
    "else:\n",
    "    days_per_id = pd.Series(0, index=df['id'].unique(), name='DaysOnChart').astype(int)\n",
    "\n",
    "# ========= Step 2: Rank（历史最优名次）=========\n",
    "peak_rank = (df.dropna(subset=['Rank'])\n",
    "               .groupby('id')['Rank']\n",
    "               .min()\n",
    "               .rename('Rank'))\n",
    "\n",
    "# ========= Step 3: Artists / Nationality 聚合（无弃用警告 + 进度条）=========\n",
    "# 说明：使用 groupby 后“显式选择列”再 apply，避免 DataFrameGroupBy.apply 的弃用警告\n",
    "\n",
    "# 3.1 艺人集合\n",
    "if has_single_artist and has_artists:\n",
    "    # 同时利用单艺人列 & 多艺人拼接列\n",
    "    grp = df.groupby('id')[['Artists', 'Artist (Ind.)']]\n",
    "    def collect_artists(g):\n",
    "        single = [a for a in g['Artist (Ind.)'].astype(str) if pd.notna(a) and a.strip()]\n",
    "        multi  = sum([split_artists(x) for x in g['Artists'].astype(str)], [])\n",
    "        # 去空格（名字内部空格去掉保持一致性，可按需调整）\n",
    "        merged = [s.replace(' ', '') for s in (single + multi) if s.strip()]\n",
    "        return uniq_preserve_order(merged)\n",
    "    artists_per_id = grp.progress_apply(collect_artists).rename('Artists')\n",
    "\n",
    "elif has_single_artist:\n",
    "    grp = df.groupby('id')[['Artist (Ind.)']]\n",
    "    def collect_artists_single(g):\n",
    "        single = [a for a in g['Artist (Ind.)'].astype(str) if pd.notna(a) and a.strip()]\n",
    "        merged = [s.replace(' ', '') for s in single]\n",
    "        return uniq_preserve_order(merged)\n",
    "    artists_per_id = grp.progress_apply(collect_artists_single).rename('Artists')\n",
    "\n",
    "elif has_artists:\n",
    "    grp = df.groupby('id')[['Artists']]\n",
    "    def collect_artists_multi(g):\n",
    "        multi  = sum([split_artists(x) for x in g['Artists'].astype(str)], [])\n",
    "        merged = [s.replace(' ', '') for s in multi]\n",
    "        return uniq_preserve_order(merged)\n",
    "    artists_per_id = grp.progress_apply(collect_artists_multi).rename('Artists')\n",
    "\n",
    "else:\n",
    "    # 都没有，则为空\n",
    "    artists_per_id = pd.Series([[]]*df['id'].nunique(),\n",
    "                               index=df['id'].drop_duplicates().tolist(),\n",
    "                               name='Artists')\n",
    "\n",
    "# 3.2 国籍集合\n",
    "if has_single_nat:\n",
    "    grp_nat = df.groupby('id')[['Nationality']]\n",
    "    def collect_nat(g):\n",
    "        vals = [n for n in g['Nationality'].astype(str) if pd.notna(n) and n.strip()]\n",
    "        return uniq_preserve_order(vals)\n",
    "    nationality_per_id = grp_nat.progress_apply(collect_nat).rename('Nationality')\n",
    "else:\n",
    "    nationality_per_id = pd.Series([[]]*df['id'].nunique(),\n",
    "                                   index=df['id'].drop_duplicates().tolist(),\n",
    "                                   name='Nationality')\n",
    "\n",
    "# ========= Step 4: 数值特征均值（按 id）=========\n",
    "agg_num_cols = ['Danceability','Energy','Valence','Loudness','Speechiness','Acousticness','Instrumentalness']\n",
    "num_mean = df.groupby('id')[agg_num_cols].mean()\n",
    "\n",
    "# ========= Step 5: 标题取第一条 =========\n",
    "title_first = df.groupby('id')['Title'].first()\n",
    "\n",
    "# ========= Step 6: 汇总到歌曲级 =========\n",
    "grouped = pd.concat([title_first, artists_per_id, nationality_per_id, num_mean], axis=1).reset_index()\n",
    "\n",
    "# 字段串联（最终存成字符串，Artists 去掉内部空格、空格分隔；Nationality 保留原文本，空格分隔）\n",
    "grouped['Artists'] = grouped['Artists'].apply(lambda lst: ', '.join(lst) if isinstance(lst, list) else '')\n",
    "grouped['Nationality'] = grouped['Nationality'].apply(lambda lst: ', '.join(lst) if isinstance(lst, list) else '')\n",
    "\n",
    "# ========= Step 7: Min-Max 归一化 =========\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "grouped[agg_num_cols] = scaler.fit_transform(grouped[agg_num_cols])\n",
    "\n",
    "# ========= Step 8: 合并 Rank / DaysOnChart =========\n",
    "grouped = (grouped\n",
    "           .merge(peak_rank, on='id', how='left')\n",
    "           .merge(days_per_id, on='id', how='left'))\n",
    "\n",
    "# 缺失兜底\n",
    "if grouped['Rank'].isna().any():\n",
    "    # 若全空则置0；否则用已知最大值兜底\n",
    "    fallback = grouped['Rank'].max() if grouped['Rank'].notna().any() else 0\n",
    "    grouped['Rank'] = grouped['Rank'].fillna(fallback)\n",
    "grouped['Rank'] = grouped['Rank'].astype(int, errors='ignore')\n",
    "grouped['DaysOnChart'] = grouped['DaysOnChart'].fillna(0).astype(int)\n",
    "\n",
    "# ========= Step 9: 输出 =========\n",
    "final_cols = [\n",
    "    'id', 'Title', 'Artists', 'Nationality',\n",
    "    'Danceability','Energy','Valence','Loudness','Speechiness','Acousticness','Instrumentalness',\n",
    "    'Rank','DaysOnChart'\n",
    "]\n",
    "final_df = grouped[final_cols].copy()\n",
    "\n",
    "final_df.to_csv(OUT, index=False, encoding='utf-8')\n",
    "print(f\"✅ 预处理完成：{OUT}  共 {len(final_df)} 首歌\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fff03f-7107-4cec-8ec1-42dca04dc241",
   "metadata": {},
   "source": [
    "将数据集分成训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5309c65e-c939-4eef-8a7b-ed0b3ba2bd38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21c3ca-f129-4815-914c-827708ca6d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
